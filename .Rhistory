# - Predict on test set
my_cart1_pred <-predict(my_cart1,current_dataset_test, type = "raw")
# - Performance on test set
confusionMatrix(my_cart1_pred,yvar_test, positive = "1")
# - Variable importance measures
plot(varImp(my_cart1))
# - CP table for each tree. Note that the complexity parameter behaviour for each tree in the
# forest is not the same
my_cart1_model$trees[[1]]$cptable
my_cart1_model$trees[[2]]$cptable
# -  Beta weight each tree by ADABoost M1
my_cart1_model$weights
my_cart1_model <- my_cart1$finalModel
names(my_cart1_model)
# - Visualize each tree of the ensemble
rpart.plot(my_cart1_model$trees[[1]],roundint=FALSE)
rpart.plot(my_cart1_model$trees[[2]],roundint=FALSE)
rpart.plot(my_cart1_model$trees[[3]],roundint=FALSE)
# - Visualize each tree of the ensemble
rpart.plot(my_cart1_model$trees[[1]],roundint=FALSE)
rpart.plot(my_cart1_model$trees[[2]],roundint=FALSE)
rpart.plot(my_cart1_model$trees[[3]],roundint=FALSE)
# - Fitted and Predicted
my_cart1_fitted <-predict(my_cart1,current_dataset_train, type = "raw")
my_cart1_pred <-predict(my_cart1,current_dataset_test, type = "raw")
# - Confusion matrices
confusion_train <- confusionMatrix(my_cart1_fitted,yvar, positive = "1")
confusion_test <- confusionMatrix(my_cart1_pred,yvar_test, positive = "1")
confusion_train
confusion_test
confusion_train
names(confusion_train)
confusion_train$byClass
names(confusion_train)
confusion_train$overall
confusion_train$byClass
names(confusion_train$byClass)
class(confusion_train$byClass)
confusion_train$byClass[1:2]
confusion_train$overall[1:2]
confusion_train$overall[1]
data.table(Type = "Training",
N = nrow(current_dataset_train),
Accuracy = confusion_train$overall[1],
Sensitivity = confusion_train$byClass[1],
Specificity = confusion_train$byClass[2])
rbind(data.table(Type = "Training",
N = nrow(current_dataset_train),
Accuracy = confusion_train$overall[1],
Sensitivity = confusion_train$byClass[1],
Specificity = confusion_train$byClass[2]),
data.table(Type = "Test",
N = nrow(current_dataset_test),
Accuracy = confusion_test$overall[1],
Sensitivity = confusion_test$byClass[1],
Specificity = confusion_test$byClass[2]))
my_cart1_model$importance
sort(my_cart1_model$importance)
data.table(sort(my_cart1_model$importance, decreasing = T))
my_varimp <- sort(my_cart1_model$importance, decreasing = T)
data.table(names(my_varimp), my_varimp)
data.table(Variable = names(my_varimp), Importance = my_varimp)
my_varimp <- sort(my_cart1_model$importance, decreasing = T)
my_cart1_varimp <- data.table(Variable = names(my_varimp), Importance = my_varimp)
my_cart1_model$trees[[1]]
my_cart1_model$trees[[1]]
class(my_cart1_model$trees[[1]])
varImp(my_cart1_model$trees[[1]])
my_cart1_varimp
my_varimp_tree1 <- sort(varImp(my_cart1_model$trees[[1]]), decreasing = T)
varImp(my_cart1_model$trees[[1]])
class(varImp(my_cart1_model$trees[[1]]))
my_varimp_tree1 <- sort(varImp(my_cart1_model$trees[[1]])$Overall, decreasing = T)
my_varimp_tree1
my_varimp_tree1/my_varimp_tree1[1]
my_varimp
my_varimp <- sort(my_cart1_model$importance, decreasing = T)
my_cart1_varimp_all <- data.table(Tree = "RF", Variable = names(my_varimp), Importance = my_varimp/my_varimp[1])
my_cart1_varimp_all
rownames(my_cart1_model$trees[[1]])
row.names(my_cart1_model$trees[[1]])
rownames(varImp(my_cart1_model$trees[[1]]))
my_varimp_tree1 <- sort(varImp(my_cart1_model$trees[[1]])$Overall, decreasing = T)
my_cart1_varimp_tree1 <- data.table(Tree = "RF", Variable = rownames(varImp(my_cart1_model$trees[[1]])), Importance = my_varimp_tree1/my_varimp_tree1[1])
my_cart1_varimp_tree1
my_cart1_varimp_tree1 <- data.table(Tree = "Tree 1", Variable = rownames(varImp(my_cart1_model$trees[[1]])), Importance = my_varimp_tree1/my_varimp_tree1[1])
my_cart1_varimp_tree1
my_varimp_tree3 <- sort(varImp(my_cart1_model$trees[[3]])$Overall, decreasing = T)
my_cart1_varimp_tree3 <- data.table(Tree = "Tree 3", Variable = rownames(varImp(my_cart1_model$trees[[3]])), Importance = my_varimp_tree3/my_varimp_tree3[1])
my_cart1_varimp_tree3
my_cart1_varimp_tree2
my_varimp_tree2 <- sort(varImp(my_cart1_model$trees[[2]])$Overall, decreasing = T)
my_cart1_varimp_tree2 <- data.table(Tree = "Tree 2", Variable = rownames(varImp(my_cart1_model$trees[[2]])), Importance = my_varimp_tree2/my_varimp_tree2[1])
my_cart1_varimp_tree2
my_cart1_varimp_all
rbind(my_varimp,my_varimp_tree1,my_varimp_tree2,my_varimp_tree3)
rbind(my_cart1_varimp_all,my_cart1_varimp_tree1,my_cart1_varimp_tree2,my_cart1_varimp_tree3)
my_varimp
varimp_summary <- rbind(my_cart1_varimp_all,my_cart1_varimp_tree1,my_cart1_varimp_tree2,my_cart1_varimp_tree3)
model_output <- list(trained_model = my_cart1,
summary_performance = my_cart1_summary_performance,
variable_importance = varimp_summary)
my_cart1_summary_performance <- rbind(data.table(Type = "Training",
N = nrow(current_dataset_train),
Accuracy = confusion_train$overall[1],
Sensitivity = confusion_train$byClass[1],
Specificity = confusion_train$byClass[2]),
data.table(Type = "Test",
N = nrow(current_dataset_test),
Accuracy = confusion_test$overall[1],
Sensitivity = confusion_test$byClass[1],
Specificity = confusion_test$byClass[2]))
my_varimp <- sort(my_cart1_model$importance, decreasing = T)
my_cart1_varimp_all <- data.table(Tree = "RF", Variable = names(my_varimp), Importance = my_varimp/my_varimp[1])
my_varimp_tree1 <- sort(varImp(my_cart1_model$trees[[1]])$Overall, decreasing = T)
my_cart1_varimp_tree1 <- data.table(Tree = "Tree 1", Variable = rownames(varImp(my_cart1_model$trees[[1]])), Importance = my_varimp_tree1/my_varimp_tree1[1])
my_varimp_tree2 <- sort(varImp(my_cart1_model$trees[[2]])$Overall, decreasing = T)
my_cart1_varimp_tree2 <- data.table(Tree = "Tree 2", Variable = rownames(varImp(my_cart1_model$trees[[2]])), Importance = my_varimp_tree2/my_varimp_tree2[1])
my_varimp_tree3 <- sort(varImp(my_cart1_model$trees[[3]])$Overall, decreasing = T)
my_cart1_varimp_tree3 <- data.table(Tree = "Tree 3", Variable = rownames(varImp(my_cart1_model$trees[[3]])), Importance = my_varimp_tree3/my_varimp_tree3[1])
varimp_summary <- rbind(my_cart1_varimp_all,my_cart1_varimp_tree1,my_cart1_varimp_tree2,my_cart1_varimp_tree3)
model_output <- list(trained_model = my_cart1,
summary_performance = my_cart1_summary_performance,
variable_importance = varimp_summary)
# -----------------------------------------------------------------------
# -------------       DATA SETS       ----------------------
# -----------------------------------------------------------------------
rm(list = ls())
# --- libraries
library(data.table)
library(caret)
# --- read datasets with fread function
credit <- fread("data/credit-data/credit-data.csv", sep = ";") # Yvar: Sale_MF (binary)
breast <- fread("data/breast-cancer-data/breast-cancer-data.csv", sep = ";") # Yvar: diagnosis (binary)
spectra_train <- fread("data/spectroscopy-data/spectra_train.csv", sep = ";") # Yvar named "Y" (continuous)
spectra_test <- fread("data/spectroscopy-data/spectra_test.csv", sep = ";")
digits_71_train <- fread("data/digits-data/digits_train.csv", sep = ";") # Yvar: one1_seven0 (binary)
digits_71_test <- fread("data/digits-data/digits_test.csv", sep = ";") # Yvar: one1_seven0
data_sets <- list(credit = credit,
breast = breast)
# - Check for missing data in each data set (spectral data has no missings)
lapply(data_sets, function(x) sum(is.na(x)))
# - Data splitting
#   Based on response variable for credit, breast and suicide
credit_trainIndex <- createDataPartition(credit[["Sale_MF"]], p = .8,
list = FALSE,
times = 1)
breast_trainIndex <- createDataPartition(breast[["diagnosis"]], p = .8,
list = FALSE,
times = 1)
credit_train <- credit[credit_trainIndex[,1]]
credit_test <- credit[-credit_trainIndex[,1]]
breast_train <- breast[breast_trainIndex[,1]]
breast_test <- breast[-breast_trainIndex[,1]]
# -----------------------------------------------------------------------
# -------------       VOTING  (PLS MODELS)      ----------------------
# -----------------------------------------------------------------------
rm(list = ls())
# --- Libraries ---
library(data.table)
library(caret)
library(ggplot2)
# --- Read data sets ---
source("01_read_data.R")
# --- Select one current dataset for work
current_dataset_train <- spectra_train
current_dataset_test <- spectra_test
current_response_var <- "Y"
yvar <- current_dataset_train[[current_response_var]]
yvar_test <- current_dataset_test[[current_response_var]]
# -------------------------- PLS MODEL TRAINING -----------------------------
# --- train Model by Tag in Caret
my_formula <- as.formula(paste0(current_response_var, " ~ ."))
# --- Model 0
# Fit a regular pls model. No preprocessing because this data is already centered and no scaling is needed.
# In PLS models (partial least squares) the tuning parameter is the number of components for dimension reduction 'ncomp'
# - CV
my_pls0_cv <- caret::train(my_formula, current_dataset_train ,method = "simpls",
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
tuneGrid=expand.grid(ncomp=1:20)
)
# CV tuning plots
my_pls0_cv_dt <- melt(my_pls0_cv$results, id.vars = "ncomp")
ggplot(my_pls0_cv_dt, aes(x = ncomp, y = value)) +
geom_line(color = "white", size = 2)+
facet_wrap(~variable, nrow = 3, ncol=2, scales = "free")+
theme_dark()+
ggtitle("PLS tuning number of components")
# - Train
my_pls0 <- caret::train(my_formula, current_dataset_train ,method = "simpls",
trControl = trainControl(
method = "cv", number = 10, verboseIter = FALSE),
tuneGrid=expand.grid(ncomp=10)
)
my_pls0
my_pls0_pred <-predict(my_pls0,current_dataset_test)
my_pls0_rmsep <- round(sqrt(mean((yvar_test - my_pls0_pred)^2)),6)
my_pls0_pred_dt <- data.table(observed = yvar_test,
predicted = my_pls0_pred)
ggplot(my_pls0_pred_dt, aes(x = observed, y = predicted))+
geom_point(colour = "red", size = 2)+
geom_segment(x = min(my_pls0_pred_dt[["observed"]]),
y = min(my_pls0_pred_dt[["predicted"]]),
xend = max(my_pls0_pred_dt[["observed"]]),
yend = max(my_pls0_pred_dt[["predicted"]]), colour = "blue")+
ggtitle("Observed vs Predicted in test set")+
geom_text(aes(x = quantile(yvar_test,0.3),y = quantile(my_pls0_pred,0.9),
label = paste0("RMSEP: ", my_pls0_rmsep)))
id1 <- (rbinom(length(yvar),1,0.5) == 1)
id2 <- (yvar >= median(yvar))
current_dataset_train1 <- current_dataset_train[id1]
current_dataset_train2 <- current_dataset_train[id2]
my_pls1_cv <- caret::train(my_formula, current_dataset_train1 ,method = "simpls",
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
tuneGrid=expand.grid(ncomp=1:20)
)
my_pls1_cv_dt <- melt(my_pls1_cv$results, id.vars = "ncomp")
ggplot(my_pls1_cv_dt, aes(x = ncomp, y = value)) +
geom_line(color = "white", size = 2)+
facet_wrap(~variable, nrow = 3, ncol=2, scales = "free")+
theme_dark()+
ggtitle("PLS tuning number of components train1")
my_pls1 <- caret::train(my_formula, current_dataset_train1 ,method = "simpls",
trControl = trainControl(
method = "cv", number = 10, verboseIter = FALSE),
tuneGrid=expand.grid(ncomp=10)
)
my_pls1
my_pls1_pred <-predict(my_pls1,current_dataset_test)
my_pls2_cv <- caret::train(my_formula, current_dataset_train2 ,method = "simpls",
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
tuneGrid=expand.grid(ncomp=1:20)
)
my_pls2_cv_dt <- melt(my_pls2_cv$results, id.vars = "ncomp")
ggplot(my_pls2_cv_dt, aes(x = ncomp, y = value)) +
geom_line(color = "white", size = 2)+
facet_wrap(~variable, nrow = 3, ncol=2, scales = "free")+
theme_dark()+
ggtitle("PLS tuning number of components train2")
my_pls2 <- caret::train(my_formula, current_dataset_train2 ,method = "simpls",
trControl = trainControl(
method = "cv", number = 10, verboseIter = FALSE),
tuneGrid=expand.grid(ncomp=9)
)
my_pls2
my_pls2_pred <-predict(my_pls2,current_dataset_test)
my_pls12_pred <- 0.5*my_pls1_pred + 0.5*my_pls2_pred
my_pls12_rmsep <- round(sqrt(mean((yvar_test - my_pls12_pred)^2)),6)
my_pls12_pred_dt <- data.table(observed = current_dataset_test[[current_response_var]],
predicted = my_pls12_pred)
ggplot(my_pls12_pred_dt, aes(x = observed, y = predicted))+
geom_point(colour = "red", size = 2)+
geom_segment(x = min(my_pls0_pred_dt[["observed"]]),
y = min(my_pls0_pred_dt[["predicted"]]),
xend = max(my_pls0_pred_dt[["observed"]]),
yend = max(my_pls0_pred_dt[["predicted"]]), colour = "blue")+
ggtitle("Observed vs Predicted in test set by voting")+
geom_text(aes(x = quantile(yvar_test,0.3),y = quantile(my_pls12_pred,0.9),
label = paste0("RMSEP: ", my_pls12_rmsep)))
my_pls0_pred_dt[["model"]] <- "unique"
my_pls12_pred_dt[["model"]] <- "ensemble"
my_pls012_pred_dt <- rbind(my_pls0_pred_dt, my_pls12_pred_dt)
p <- ggplot(my_pls012_pred_dt, aes(x = observed, y = predicted))+
geom_point(colour = "red", size = 2)+
geom_segment(x = min(my_pls0_pred_dt[["observed"]]),
y = min(my_pls0_pred_dt[["predicted"]]),
xend = max(my_pls0_pred_dt[["observed"]]),
yend = max(my_pls0_pred_dt[["predicted"]]), colour = "blue")+
ggtitle("Observed vs Predicted in test set - animation- ")+
facet_wrap(~model)
p
# -----------------------------------------------------------------------
# -------------       BAGGING - RANDOM FORESTS       --------------------
# -----------------------------------------------------------------------
rm(list = ls())
# --- Libraries ---
library(data.table)
library(caret)
library(ggplot2)
library(rpart.plot)
library(randomForest)
library(ipred)
# --- Read data sets ---
source("01_read_data.R")
# --- Select one current dataset for work
current_dataset_train <- credit_train
current_dataset_test <- credit_test
current_response_var <- "Sale_MF"
current_dataset_train[[current_response_var]] <- as.factor(current_dataset_train[[current_response_var]])
current_dataset_test[[current_response_var]] <- as.factor(current_dataset_test[[current_response_var]])
yvar <- current_dataset_train[[current_response_var]]
yvar_test <- current_dataset_test[[current_response_var]]
# --------------------------------- CART MODEL TRAINING --------------------------
my_formula <- as.formula(paste0(current_response_var, " ~ ."))
my_cart0 <- caret::train(my_formula, current_dataset_train, method = "rpart",model=TRUE,
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
tuneGrid=expand.grid(cp=0.005)
)
# - Plot the tree
rpart.plot(my_cart0$finalModel)
# - CP table
my_cart0$finalModel$cptable
# - Prediction on test set
my_cart0_pred <-predict(my_cart0,current_dataset_test)
# - Performance on test set
confusionMatrix(my_cart0_pred,yvar_test, positive = "1")
my_cart1 <- caret::train(my_formula, current_dataset_train, method = "treebag",
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
nbagg = 4
)
# - Retrive actual final forest
my_cart1_model<- my_cart1$finalModel
# - Visualize one particular tree of the forest
rpart.plot(my_cart1_model$mtrees[[1]]$btree)
# - Predict on test set
my_cart1_pred <-predict(my_cart1,current_dataset_test, type = "raw")
# - Performance on test set
confusionMatrix(my_cart1_pred,yvar_test, positive = "1")
# - Variable importance measures
plot(varImp(my_cart1))
# - CP table for each tree. Note that the complexity parameter behaviour for each tree in the
# forest is not the same
my_cart1_model$mtrees[[1]]$btree$cptable
my_cart1_model$mtrees[[2]]$btree$cptable
my_cart1_model$mtrees[[3]]$btree$cptable
my_cart1_model$mtrees[[4]]$btree$cptable
my_cart2 <- caret::train(my_formula, current_dataset_train, method = "rf",
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
ntree = 4,
tuneGrid=expand.grid(mtry=5:28),
keep.forest = TRUE
)
# - Retrieve final model
my_cart2_model <- my_cart2$finalModel
# - Predict on test set
my_cart2_pred <-predict(my_cart2,current_dataset_test)
# - Performance on test set
confusionMatrix(my_cart2_pred,yvar_test, positive = "1")
# - Variable importance plot
plot(varImp(my_cart2))
# - Number of trees grown
my_cart2_model$ntree
# - Matrix depicting a selected tree of the forest
getTree(my_cart2_model, k=1, labelVar = T)
# --------------------------------------------------------------------------------------------------------------------------------------
# -------------       BOOSTING - DIGIT RECOGNITION (differentiate number "1" and "7" in pictures)      ----------------------------
# --- Algorithm found in:  N. Abdul Rahim et al.  /  Procedia Engineering   53  ( 2013 )  411 – 419
# ---      Adaptive Boosting with SVM Classifier for Moving Vehicle Classification
# ----------------------------------------------------------------------------------------------------------------------------------------
rm(list = ls())
# --- Libraries ---
library(data.table)
library(caret)
library(ggplot2)
library(jpeg)
# --- Read data sets ---
source("01_read_data.R")
# --- Select one current dataset for work
current_dataset_train <- digits_71_train
current_dataset_test <- digits_71_test
current_response_var <- "one1_seven0"
current_dataset_train[[current_response_var]] <- as.factor(current_dataset_train[[current_response_var]])
current_dataset_test[[current_response_var]] <- as.factor(current_dataset_test[[current_response_var]])
yvar <- current_dataset_train[[current_response_var]]
yvar_test <- current_dataset_test[[current_response_var]]
# --- Model formula
my_formula <- as.formula(paste0(current_response_var, " ~ ."))
nIters <- 5
my_reg_models <- list()
my_reg_models_beta <- numeric(nIters)
Ntrain <- nrow(current_dataset_train)
all_samples <- seq(1, Ntrain)
all_samples_prob <- rep(1/Ntrain,Ntrain)
itt <- 1
while(itt <= nIters){
cat("----------------------- SVM Model ", itt, "--------------------------")
selected_samples <- sample(x = all_samples, size = floor(Ntrain*0.8), prob = all_samples_prob,replace = TRUE)
# --- SVM model
my_reg0 <- caret::train(my_formula, current_dataset_train[selected_samples], method = "svmRadialCost",model=TRUE,
trControl = trainControl(
method = "cv", number = 2, verboseIter = FALSE),
tuneGrid=expand.grid(C = 10)
)
# - Final model
my_reg_models[[itt]] <- my_reg0
my_reg0_fitted <-predict(my_reg0,current_dataset_train)
my_reg0_errors <- (my_reg0_fitted != yvar)
confusion_m <- confusionMatrix(my_reg0_fitted, yvar, positive = "1")
print(confusion_m$byClass[1:2])
# - Errors of the model
my_reg0_total_error <- sum(my_reg0_errors*all_samples_prob)
my_reg_models_beta[itt] <- my_reg0_total_error/(1-my_reg0_total_error)
# - Update distribution of weights of samples in train set
new_samples_dist <- ifelse(my_reg0_errors==1, 1,my_reg_models_beta[itt])
all_samples_prob <- new_samples_dist/sum(new_samples_dist)
itt <- itt + 1
}
nBoost <- 5
my_reg_ensemble_train <- matrix(NA, nrow = Ntrain, ncol = nBoost)
for(itt in 1:nBoost){
my_reg_ensemble_train[,itt] <- (as.numeric(predict(my_reg_models[[itt]], current_dataset_train))-1)
}
my_reg_models_beta_matrix <- matrix(log(1/my_reg_models_beta), nrow = Ntrain, ncol = nBoost, byrow = T)
betas_fitted_1 <- my_reg_ensemble_train*my_reg_models_beta_matrix
betas_fitted_0 <- (1-my_reg_ensemble_train)*my_reg_models_beta_matrix
diff_fitted <- apply(betas_fitted_1,1,sum)-apply(betas_fitted_0,1,sum)
my_reg_ensemble_final_fitted <- as.factor(ifelse(diff_fitted>0,1,0))
confusion_ensemble_fitted <- confusionMatrix(my_reg_ensemble_final_fitted, yvar, positive = "1")
print(confusion_ensemble_fitted)
iim <- 2 # Check model by model
cat("----------------------- SVM predictions model ", iim, "--------------------------")
my_reg_pred <- predict(my_reg_models[[iim]], current_dataset_test)
confusion_m_pred <- confusionMatrix(my_reg_pred, yvar_test, positive = "1")
print(confusion_m_pred$byClass[1:2])
Ntest <- nrow(current_dataset_test)
nBoost <- 2
my_reg_ensemble_pred <- matrix(NA, nrow = Ntest, ncol = nBoost)
for(itt in 1:nBoost){
my_reg_ensemble_pred[,itt] <- (as.numeric(predict(my_reg_models[[itt]], current_dataset_test))-1)
}
my_reg_models_beta_matrix <- matrix(log(1/my_reg_models_beta[1:nBoost]), nrow = Ntest, ncol = nBoost, byrow = T)
betas_predicted_1 <- my_reg_ensemble_pred*my_reg_models_beta_matrix
betas_predicted_0 <- (1-my_reg_ensemble_pred)*my_reg_models_beta_matrix
diff_pred <- apply(betas_predicted_1,1,sum)-apply(betas_predicted_0,1,sum)
my_reg_ensemble_final_pred <- as.factor(ifelse(diff_pred>0,1,0))
confusion_ensemble_pred <- confusionMatrix(my_reg_ensemble_final_pred, yvar_test, positive = "1")
print(confusion_ensemble_pred)
bitmap_test <- copy(current_dataset_test)
bitmap_test[[current_response_var]] <- NULL
image_id <- 2053
image_matrix <- matrix(as.matrix(bitmap_test[image_id]), nrow=32, ncol=32, byrow = TRUE)
yvar_test[image_id]
writeJPEG(image_matrix, paste0("figures/04_image_",as.character(image_id),".jpeg"), quality = 1)
# -----------------------------------------------------------------------
# -------------       BOOSTING - DECISION TREES      --------------------
# -----------------------------------------------------------------------
rm(list = ls())
# --- Libraries ---
library(data.table)
library(caret)
library(ggplot2)
library(rpart.plot)
library(adabag)
# --- Read data sets ---
source("01_read_data.R")
# --- Select one current dataset for work
current_dataset_train <- breast_train
current_dataset_test <- breast_test
current_response_var <- "diagnosis"
current_dataset_train[[current_response_var]] <- as.factor(current_dataset_train[[current_response_var]])
current_dataset_test[[current_response_var]] <- as.factor(current_dataset_test[[current_response_var]])
yvar <- current_dataset_train[[current_response_var]]
yvar_test <- current_dataset_test[[current_response_var]]
my_formula <- as.formula(paste0(current_response_var, " ~ ."))
my_cart0 <- caret::train(my_formula, current_dataset_train, method = "rpart",model=TRUE,
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
tuneGrid=expand.grid(cp=0.00005),
control = rpart.control(maxdepth = 20)
)
# - Plot the tree
rpart.plot(my_cart0$finalModel)
# - CP table
my_cart0$finalModel$cptable
# - Prediction on test set
my_cart0_pred <-predict(my_cart0,current_dataset_test)
# - Performance on test set
confusionMatrix(my_cart0_pred,yvar_test, positive = "1")
my_cart1 <- caret::train(my_formula, current_dataset_train, method = "AdaBoost.M1",
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
tuneGrid=expand.grid(mfinal = 2, coeflearn = "Breiman", maxdepth = 5),
boos = TRUE
)
# - Retrive actual final forest
my_cart1_model <- my_cart1$finalModel
# - Performance on test set
confusionMatrix(my_cart0_pred,yvar_test, positive = "1")
# - Performance on test set
confusionMatrix(my_cart0_pred,yvar_test, positive = "1")
my_cart1 <- caret::train(my_formula, current_dataset_train, method = "AdaBoost.M1",
trControl = trainControl(
method = "cv", number = 10, verboseIter = TRUE),
tuneGrid=expand.grid(mfinal = 2, coeflearn = "Breiman", maxdepth = 5),
boos = TRUE
)
# - Retrive actual final forest
my_cart1_model <- my_cart1$finalModel
# - Visualize each tree of the ensemble
rpart.plot(my_cart1_model$trees[[1]],roundint=FALSE)
rpart.plot(my_cart1_model$trees[[2]],roundint=FALSE)
# - Predict on test set
my_cart1_pred <-predict(my_cart1,current_dataset_test, type = "raw")
# - Performance on test set
confusionMatrix(my_cart1_pred,yvar_test, positive = "1")
# - Variable importance measures
plot(varImp(my_cart1))
# - CP table for each tree. Note that the complexity parameter behaviour for each tree in the
# forest is not the same
my_cart1_model$trees[[1]]$cptable
my_cart1_model$trees[[2]]$cptable
# -  Beta weight each tree by ADABoost M1
my_cart1_model$weights
library(shiny); runApp('breast_cancer_analyser/app_model.R')
runApp('breast_cancer_analyser/app_prototype.R')
library(shiny); runApp('breast_cancer_analyser/app_prototype.R')
